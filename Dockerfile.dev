
# Use an official Node.js runtime as a base image.
# This tells Docker to use an existing Node.js image as the base for our custom image. This base image has Node.js pre-installed.
FROM node:14-alpine AS development

# We set the node environment variable
ENV NODE_ENV development

# Set the current working directory inside the docker container to app
WORKDIR /app

# Copy package.json and package-lock.json to the working directory. This file contains the dependencies for our Node.js app.
COPY package*.json ./

# Cache and Install dependencies
# COPY yarn.lock .

#RUN yarn install
RUN npm install

# Copy everything from the current working directory of the host machine to the working directory inside the container ( which is app in this case ).
# This step is not necessary for the development Dockerfile though. We will map the host working directory to the containers working directory
# in the docker-compose.yml file anyway. But I like to keep this line here because in the future we may use this Dockerfile for production 
# or take this Dockerfile as an inspiration to create the production Dockerfile. 
# In that case, this line will work as a reminder that we need to copy the source code into the container.
COPY . .

# Expose the port the app runs on. This Informs Docker that the container will use port 3000
EXPOSE 3000

# This Specifies the command to Start the app
CMD [ "npm", "start" ]




# Create a docker-compose.dev.yml. Additionally, we will mount our code in a volume so that our code changes are in sync with the container during development.


# NOTE : above code is not multi-stage build. If see its image size then it will be of 500mb.
# To use multi-stage build , below is the code : This code will reduce the image size from 500 to 300 mb


# This is the first stage which is responsible for the installation of dependencies.

# FROM node:14-alpine AS development
# ENV NODE_ENV development
# WORKDIR /app
# COPY package*.json ./
# RUN npm install
# COPY . .

# # This is the Second stage : use lightweight runtime image.
# FROM node:lts-alpine AS developmentTwo
# WORKDIR /app

# Here it is copying only built files and dependencies from first stage. 
# COPY --from=development /app /app/


# EXPOSE 3000

# CMD [ "npm", "start" ]



#                   What is the Multi-Stage build here? ğŸ‘€
# - We use the previously built files. The thing is Dockerfile is nothing but multiple layers right,
#  assuming when there are no changes in the first 3 layers, we use the layers of previous builds to reduce spending time for those layers again.




# NOTE:

#    ğ“ğ¡ğ ğğ¨ğ°ğğ« ğ¨ğŸ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬.

# Large Docker images slow deployments, waste storage, and increase vulnerabilities.
# Multi-Stage Builds optimize images by splitting the process into stages, keeping only essentials in the final lightweight image, improving speed, security, and maintainability.

#    ğ–ğ¡ğšğ­ ğ€ğ«ğ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬?
# Multi-Stage Builds let you use multiple FROM instructions in a single Dockerfile, each representing a different stage.
# This allows you to compile or build your application in one stage and copy only the necessary output into the final, lightweight image.

#    ğ–ğ¡ğ² ğ”ğ¬ğ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬â“

# âœ…ğƒğ«ğšğ¬ğ­ğ¢ğœğšğ¥ğ¥ğ² ğ‘ğğğ®ğœğ ğˆğ¦ğšğ ğ ğ’ğ¢ğ³ğ: By excluding unnecessary build dependencies, multi-stage builds keep only the essentials in your final image,
#  shrinking its size by up to 50% or more.

# âœ…ğ„ğ§ğ¡ğšğ§ğœğğ ğ’ğğœğ®ğ«ğ¢ğ­ğ²: A smaller image has fewer layers and dependencies, reducing the attack surface and the risk of vulnerabilities.

# âœ…ğ…ğšğ¬ğ­ğğ« ğƒğğ©ğ¥ğ¨ğ²ğ¦ğğ§ğ­ğ¬: Smaller images mean quicker downloads and deployments, speeding up your CI/CD pipelines.

# âœ…ğ’ğ¢ğ¦ğ©ğ¥ğ¢ğŸğ¢ğğ ğŒğšğ¢ğ§ğ­ğğ§ğšğ§ğœğ: With separate stages for building and production, your Docker file becomes cleaner and easier to manage.



#  ğ–ğ¨ğ§ğğğ«ğ¢ğ§ğ  ğ–ğ¡ğ² ğˆğ­'ğ¬ ğš ğ†ğšğ¦ğ ğ‚ğ¡ğšğ§ğ ğğ«â“

# With Multi-Stage Builds, youâ€™re not just reducing image sizeâ€”youâ€™re also improving security, boosting deployment speeds, and making your Dockerfiles more maintainable.
#  Itâ€™s a win-win for developers and operations teams alike.
