
# Use an official Node.js runtime as a base image.
# This tells Docker to use an existing Node.js image as the base for our custom image. This base image has Node.js pre-installed.
FROM node:14-alpine AS development

# We set the node environment variable.
# The ENV NODE_ENV=development instruction in a Dockerfile sets an environment variable that affects how Node.js applications behave.
# 1. Creates an environment variable named NODE_ENV.
# 2. Sets its value to "development".
# 3. This variable persists inside the container.
# 4. inside you code you check this by : console.log( process.env.NODE_ENV ) 

ENV NODE_ENV development

# We You can override it when running the container :
# docker run -e NODE_ENV=production your-image-name

# Set the current working directory inside the docker container to app
WORKDIR /app

# Copy package.json and package-lock.json to the working directory. This file contains the dependencies for our Node.js app.
COPY package*.json ./

# Cache and Install dependencies
# COPY yarn.lock .

#RUN yarn install
RUN npm install

# Copy everything from the current working directory of the host machine to the working directory inside the container ( which is app in this case ).
# This step is not necessary for the development Dockerfile though. We will map the host working directory to the containers working directory
# in the docker-compose.yml file anyway. But I like to keep this line here because in the future we may use this Dockerfile for production 
# or take this Dockerfile as an inspiration to create the production Dockerfile. 
# In that case, this line will work as a reminder that we need to copy the source code into the container.
COPY . .

# Expose the port the app runs on. This Informs Docker that the container will use port 3000.
# The EXPOSE 3000 instruction in a Dockerfile is a form of documentation that declares which port(s) the container will listen on at runtime. In this case, it indicates that the application inside the container will be listening on port 3000.
# However, it's important to understand that:
# 1. EXPOSE is primarily documentation - it doesn't actually publish or open the port
# 2. It serves as metadata about the container
# 3. It doesn't automatically map the port to your host machine
EXPOSE 3000

# This Specifies the command to Start the app
CMD [ "npm", "start" ]




# Create a docker-compose.dev.yml. Additionally, we will mount our code in a volume so that our code changes are in sync with the container during development.


# NOTE : above code is not multi-stage build. If see its image size then it will be of 500mb.
# To use multi-stage build , below is the code : This code will reduce the image size from 500 to 300 mb


# This is the first stage which is responsible for the installation of dependencies.

# FROM node:14-alpine AS development
# ENV NODE_ENV development
# WORKDIR /app
# COPY package*.json ./
# RUN npm install
# COPY . .

# # This is the Second stage : use lightweight runtime image.
# FROM node:lts-alpine AS developmentTwo
# WORKDIR /app

# Here it is copying only built files and dependencies from first stage. 
# COPY --from=development /app /app/


# EXPOSE 3000

# CMD [ "npm", "start" ]



#                   What is the Multi-Stage build here? 👀
# - We use the previously built files. The thing is Dockerfile is nothing but multiple layers right,
#  assuming when there are no changes in the first 3 layers, we use the layers of previous builds to reduce spending time for those layers again.




# NOTE:

#    𝐓𝐡𝐞 𝐏𝐨𝐰𝐞𝐫 𝐨𝐟 𝐌𝐮𝐥𝐭𝐢-𝐒𝐭𝐚𝐠𝐞 𝐁𝐮𝐢𝐥𝐝𝐬.

# Large Docker images slow deployments, waste storage, and increase vulnerabilities.
# Multi-Stage Builds optimize images by splitting the process into stages, keeping only essentials in the final lightweight image, improving speed, security, and maintainability.

#    𝐖𝐡𝐚𝐭 𝐀𝐫𝐞 𝐌𝐮𝐥𝐭𝐢-𝐒𝐭𝐚𝐠𝐞 𝐁𝐮𝐢𝐥𝐝𝐬?
# Multi-Stage Builds let you use multiple FROM instructions in a single Dockerfile, each representing a different stage.
# This allows you to compile or build your application in one stage and copy only the necessary output into the final, lightweight image.

#    𝐖𝐡𝐲 𝐔𝐬𝐞 𝐌𝐮𝐥𝐭𝐢-𝐒𝐭𝐚𝐠𝐞 𝐁𝐮𝐢𝐥𝐝𝐬❓

# ✅𝐃𝐫𝐚𝐬𝐭𝐢𝐜𝐚𝐥𝐥𝐲 𝐑𝐞𝐝𝐮𝐜𝐞 𝐈𝐦𝐚𝐠𝐞 𝐒𝐢𝐳𝐞: By excluding unnecessary build dependencies, multi-stage builds keep only the essentials in your final image,
#  shrinking its size by up to 50% or more.

# ✅𝐄𝐧𝐡𝐚𝐧𝐜𝐞𝐝 𝐒𝐞𝐜𝐮𝐫𝐢𝐭𝐲: A smaller image has fewer layers and dependencies, reducing the attack surface and the risk of vulnerabilities.

# ✅𝐅𝐚𝐬𝐭𝐞𝐫 𝐃𝐞𝐩𝐥𝐨𝐲𝐦𝐞𝐧𝐭𝐬: Smaller images mean quicker downloads and deployments, speeding up your CI/CD pipelines.

# ✅𝐒𝐢𝐦𝐩𝐥𝐢𝐟𝐢𝐞𝐝 𝐌𝐚𝐢𝐧𝐭𝐞𝐧𝐚𝐧𝐜𝐞: With separate stages for building and production, your Docker file becomes cleaner and easier to manage.



#  𝐖𝐨𝐧𝐝𝐞𝐫𝐢𝐧𝐠 𝐖𝐡𝐲 𝐈𝐭'𝐬 𝐚 𝐆𝐚𝐦𝐞 𝐂𝐡𝐚𝐧𝐠𝐞𝐫❓

# With Multi-Stage Builds, you’re not just reducing image size—you’re also improving security, boosting deployment speeds, and making your Dockerfiles more maintainable.
#  It’s a win-win for developers and operations teams alike.
