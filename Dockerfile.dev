
# Use an official Node.js runtime as a base image.
# This tells Docker to use an existing Node.js image as the base for our custom image. This base image has Node.js pre-installed.
FROM node:14-alpine AS development

# We set the node environment variable.
# The ENV NODE_ENV=development instruction in a Dockerfile sets an environment variable that affects how Node.js applications behave.
# 1. Creates an environment variable named NODE_ENV.
# 2. Sets its value to "development".
# 3. This variable persists inside the container.
# 4. inside you code you check this by : console.log( process.env.NODE_ENV ) 

ENV NODE_ENV development

# We You can override it when running the container :
# docker run -e NODE_ENV=production your-image-name

# Set the current working directory inside the docker container to app
WORKDIR /app

# Copy package.json and package-lock.json to the working directory. This file contains the dependencies for our Node.js app.
COPY package*.json ./

# Cache and Install dependencies
# COPY yarn.lock .

#RUN yarn install
RUN npm install

# Copy everything from the current working directory of the host machine to the working directory inside the container ( which is app in this case ).
# This step is not necessary for the development Dockerfile though. We will map the host working directory to the containers working directory
# in the docker-compose.yml file anyway. But I like to keep this line here because in the future we may use this Dockerfile for production 
# or take this Dockerfile as an inspiration to create the production Dockerfile. 
# In that case, this line will work as a reminder that we need to copy the source code into the container.
COPY . .

# Expose the port the app runs on. This Informs Docker that the container will use port 3000.
# The EXPOSE 3000 instruction in a Dockerfile is a form of documentation that declares which port(s) the container will listen on at runtime. In this case, it indicates that the application inside the container will be listening on port 3000.
# However, it's important to understand that:
# 1. EXPOSE is primarily documentation - it doesn't actually publish or open the port
# 2. It serves as metadata about the container
# 3. It doesn't automatically map the port to your host machine
EXPOSE 3000

# This Specifies the command to Start the app
CMD [ "npm", "start" ]




# Create a docker-compose.dev.yml. Additionally, we will mount our code in a volume so that our code changes are in sync with the container during development.


# NOTE : above code is not multi-stage build. If see its image size then it will be of 500mb.
# To use multi-stage build , below is the code : This code will reduce the image size from 500 to 300 mb


# This is the first stage which is responsible for the installation of dependencies.

# FROM node:14-alpine AS development
# ENV NODE_ENV development
# WORKDIR /app
# COPY package*.json ./
# RUN npm install
# COPY . .

# # This is the Second stage : use lightweight runtime image.
# FROM node:lts-alpine AS developmentTwo
# WORKDIR /app

# Here it is copying only built files and dependencies from first stage. 
# COPY --from=development /app /app/


# EXPOSE 3000

# CMD [ "npm", "start" ]



#                   What is the Multi-Stage build here? ğŸ‘€
# - We use the previously built files. The thing is Dockerfile is nothing but multiple layers right,
#  assuming when there are no changes in the first 3 layers, we use the layers of previous builds to reduce spending time for those layers again.




# NOTE:

#    ğ“ğ¡ğ ğğ¨ğ°ğğ« ğ¨ğŸ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬.

# Large Docker images slow deployments, waste storage, and increase vulnerabilities.
# Multi-Stage Builds optimize images by splitting the process into stages, keeping only essentials in the final lightweight image, improving speed, security, and maintainability.

#    ğ–ğ¡ğšğ­ ğ€ğ«ğ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬?
# Multi-Stage Builds let you use multiple FROM instructions in a single Dockerfile, each representing a different stage.
# This allows you to compile or build your application in one stage and copy only the necessary output into the final, lightweight image.

#    ğ–ğ¡ğ² ğ”ğ¬ğ ğŒğ®ğ¥ğ­ğ¢-ğ’ğ­ğšğ ğ ğğ®ğ¢ğ¥ğğ¬â“

# âœ…ğƒğ«ğšğ¬ğ­ğ¢ğœğšğ¥ğ¥ğ² ğ‘ğğğ®ğœğ ğˆğ¦ğšğ ğ ğ’ğ¢ğ³ğ: By excluding unnecessary build dependencies, multi-stage builds keep only the essentials in your final image,
#  shrinking its size by up to 50% or more.

# âœ…ğ„ğ§ğ¡ğšğ§ğœğğ ğ’ğğœğ®ğ«ğ¢ğ­ğ²: A smaller image has fewer layers and dependencies, reducing the attack surface and the risk of vulnerabilities.

# âœ…ğ…ğšğ¬ğ­ğğ« ğƒğğ©ğ¥ğ¨ğ²ğ¦ğğ§ğ­ğ¬: Smaller images mean quicker downloads and deployments, speeding up your CI/CD pipelines.

# âœ…ğ’ğ¢ğ¦ğ©ğ¥ğ¢ğŸğ¢ğğ ğŒğšğ¢ğ§ğ­ğğ§ğšğ§ğœğ: With separate stages for building and production, your Docker file becomes cleaner and easier to manage.



#  ğ–ğ¨ğ§ğğğ«ğ¢ğ§ğ  ğ–ğ¡ğ² ğˆğ­'ğ¬ ğš ğ†ğšğ¦ğ ğ‚ğ¡ğšğ§ğ ğğ«â“

# With Multi-Stage Builds, youâ€™re not just reducing image sizeâ€”youâ€™re also improving security, boosting deployment speeds, and making your Dockerfiles more maintainable.
#  Itâ€™s a win-win for developers and operations teams alike.
